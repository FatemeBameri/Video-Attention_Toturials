# Video-Attention
Summary of related papers on vido attention. 
## Video attention Papers

1. Recurrent attention unit: A new gated recurrent unit for long-term memory of important parts in sequential data (Neurocomputing 2023) [pdf](https://www.sciencedirect.com/science/article/abs/pii/S0925231222013339)
2. Attention mechanisms in computer vision: A survey (Computational Visual Media 2022) [pdf](https://link.springer.com/article/10.1007/s41095-022-0271-y) 
3.  Attention for vision-based assistive and automated driving: A review of algorithms and datasets (IEEE Transactions on Intelligent Transportation Systems 2022) [pdf](https://ieeexplore.ieee.org/abstract/document/9827989/)
4.  Transformers in vision: A survey (ACM computing surveys 2022) [pdf](https://dl.acm.org/doi/abs/10.1145/3505244)
5.  Attention, please! A survey of neural attention models in deep learning (Artificial Intelligence Review 2022) [pdf](https://link.springer.com/article/10.1007/s10462-022-10148-x)
6. A review on the attention mechanism of deep learning (Neurocomputing 2021) [pdf](https://www.sciencedirect.com/science/article/abs/pii/S092523122100477X)
7.  An attentive survey of attention models (ACM Transactions on Intelligent Systems and Technology 2021) [pdf](https://dl.acm.org/doi/abs/10.1145/3465055)
HSTA: A hierarchical spatio-temporal attention model for trajectory prediction (IEEE Transactions on Vehicular Technology 2021) [pdf](https://ieeexplore.ieee.org/abstract/document/9548801)
8. Attention in natural language processing (IEEE transactions on neural networks and learning systems 2020) [pdf](https://ieeexplore.ieee.org/abstract/document/9194070)
9.  Attention in psychology, neuroscience, and machine learning (Frontiers in computational neuroscience 2020) [pdf](https://www.frontiersin.org/articles/10.3389/fncom.2020.00029/full)
10. Recurrent spatial-temporal attention network for action recognition in videos (IEEE Transactions on Image Processing 2017) [pdf](https://ieeexplore.ieee.org/abstract/document/8123939)
11. Efficient Transformers: A Survey (ACM Computing Surveys 2022)
12. Memorizing Transformers (ICLR 2022)
13. Rethinking Attention with Performers (ICLR 2021)
14. Random Feature Attention (ICLR 2021)
15. Sparse Sinkhorn Attention (ICML 2020)
16. Universal Transformers (ICLR 2019)
17. Survey of spatio-temporal interest point detection algorithms in video (IEEE Access 2017) [pdf](https://ieeexplore.ieee.org/abstract/document/7944559)
18. Typologies of attentional networks (Nature reviews neuroscience 2006) [pdf](https://www.nature.com/articles/nrn1903)
19. Neural Machine Translation by Jointly Learning to Align and Translate
20.  Recurrent Models of Visual Attention
21.  Multiple Object Recognition with Visual Attention
22.  Effective Approaches to Attention-based Neural Machine Translation
23.  Pyramid Attention Network for Semantic Segmentation
24.  Dual Attention Network for Scene Segmentation
25.  Visual Attention Network
26. Multi-level channel attention excitation network for human action recognition in videos [pdf](https://www.sciencedirect.com/science/article/abs/pii/S092359652300022X)
27. Attention based spatiotemporal graph attention networks for traffic flow forecasting [paper](https://www.sciencedirect.com/science/article/abs/pii/S0020025522005679)


## Understanding Attention
* General meaning of attention in wikipedia [link](https://en.wikipedia.org/wiki/Attention_(machine_learning))
* Attention and Memory in Deep Learning [Youtube](https://www.youtube.com/watch?v=AIiwuClvH6k)
* Attention [Youtube](https://www.youtube.com/watch?v=YAgjfMR9R_M)
* Comprehensive Guide to Attention Mechanism [blog](https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/)
* Visualizing machine learning one concept at a time [blog](https://jalammar.github.io/)
* The Transformer Family Version 2.0 [Lil'Log](https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/)
* Attention? Attention [Lil'Log](https://lilianweng.github.io/posts/2018-06-24-attention/#a-family-of-attention-mechanisms)
* Large Transformer Model Inference Optimization [Lil'Log](https://lilianweng.github.io/posts/2023-01-10-inference-optimization/)
* The Illustrated Retrieval Transformer [Jay Alammar blog](https://jalammar.github.io/illustrated-retrieval-transformer/)
* The Illustrated GPT-2 [Jay Alammar blog](https://jalammar.github.io/illustrated-gpt2/)
* The Illustrated BERT, ELMo, and co [Jay Alammar blog](https://jalammar.github.io/illustrated-bert/)
* The Illustrated Transformer [Jay Alammar blog](https://jalammar.github.io/illustrated-transformer/)
* Transformer Architecture: The Positional Encoding [Amirhossein Kazemnejad's blog](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)
* Attention Mechanism from Scratch [link](https://machinelearningmastery.com/the-attention-mechanism-from-scratch/)
* Transformer Attention Mechanism [link](https://machinelearningmastery.com/the-transformer-attention-mechanism/)
* Positional Encoding in Transformer Models [link](https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/)
* Training the Transformer Model [link](https://machinelearningmastery.com/training-the-transformer-model/)
* Transformer Model [link](https://machinelearningmastery.com/the-transformer-model/)
* Scaled Dot-Product Attention [link](https://machinelearningmastery.com/how-to-implement-scaled-dot-product-attention-from-scratch-in-tensorflow-and-keras/)
* Attention in Long Short-Term Memory Recurrent Neural Networks [link](https://machinelearningmastery.com/attention-long-short-term-memory-recurrent-neural-networks/)
* Self-Attention In Computer Vision [Towards Data Science](https://towardsdatascience.com/self-attention-in-computer-vision-2782727021f6)
* Learn to Pay Attention! Trainable Visual Attention in CNNs [Towards Data Science](https://towardsdatascience.com/learn-to-pay-attention-trainable-visual-attention-in-cnns-87e2869f89f1)
* How can Transformers be used in Computer Vision? [Louis Bouchard](https://www.louisbouchard.ai/will-transformers-replace-cnns-for-vision/)
## Pytorch Code for Attention
* Transformers [(github)](https://github.com/huggingface/transformers)
* Attention Gated Networks [(github)](https://github.com/ozan-oktay/Attention-Gated-Networks)
* ResNeSt: Split-Attention Networks [(github)](https://github.com/zhanghang1989/ResNeSt)
* Self-Attention GAN [(github)](https://github.com/heykeetae/Self-Attention-GAN)
* Attention Transfer [(github)](https://github.com/szagoruyko/attention-transfer)
* Dual Attention Network [(github)](https://github.com/junfu1115/DANet)
* ECA-Net: Efficient Channel Attention [(github)](https://github.com/BangguWu/ECANet)
* RCAN [(github)](https://github.com/yulunzhang/RCAN)
* U-GAT-IT [(github)](https://github.com/znxlwm/UGATIT-pytorch)
* PSEnet+CRNN [(github)](https://github.com/rahzaazhar/PAN-PSEnet)
* seq2seqModel [(github)](https://github.com/sudhirNallam/seq2seqModel)
* xformers_mingpt [(colab)](https://colab.research.google.com/github/facebookresearch/xformers/blob/main/docs/source/xformers_mingpt.ipynb)

## Papers with Code
* A Structured Self-attentive Sentence Embedding [(code)](https://github.com/kaushalshetty/Structured-Self-Attention)
* SA-Net: Shuffle Attention for Deep Convolutional Neural Networks [(code)](https://github.com/wofmanaf/SA-Net)
* Contextual transformer networks for visual recognition [(code)](https://github.com/yehli/imagenetmodel)
* Fully Attentional Networks [(code)](https://github.com/nvlabs/fan)


